---
layout: post
title: "AI"
author: "Yashique Chalil"
categories: dev
tags: [dev]
image: dm-1.jpg
---

I’ve had the privilege of working extensively in neural synthesis, particularly with cutting-edge architectures like IRCAM’s RAVE, where my primary focus has been on training neural networks to capture and synthesize diverse sonic styles into AI models. My research spans across various alternative architectures, as I continually seek to develop more stable, refined models that can push the boundaries of creative sound design.

This journey has led me to collaborate with some of the leading figures in AI and music research, allowing me to merge academic rigor with innovative, artistic sound exploration. Through these partnerships, I've gained deeper insights into how neural synthesis can reshape our understanding and creation of sound.

Here are some demos of a plant model I’ve been developing. This model is trained on sounds that reflect the umwelt—the sensory world—of plants, capturing a fictional "auditory environment". My goal is to use a refined version of this model for the sound design of an upcoming audio-visual play centered around plants, where the soundscapes will reflect their rich, yet often imperceptible, sonic world.

 <div style="position:relative;padding-top:5%;">
<iframe width="100%" height="max-height" style="aspect-ratio:16 / 9;" src="https://www.youtube.com/embed/zioyLQRZVgg?si=4p9NkIpPWHLpw8ig" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<p style="text-align: center; color: gray;">Running isolated bass and drums of John Coltrane's Giant Steps, pitched down into PlantModel v1. </p>
</div>

<div style="position:relative;padding-top:5%;">
<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1906974287&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/yash-que-chalil" title="yashique" target="_blank" style="color: #cccccc; text-decoration: none;">yashique</a> · <a href="https://soundcloud.com/yash-que-chalil/xylemcombustionengine" title="xylem combustion engine" target="_blank" style="color: #cccccc; text-decoration: none;">xylem combustion engine</a>
</div>

<p style="text-align: center; color: gray;">Halucinations (The sounds that the model makes when there is no input going in) of the Plant Model V2. The variations were performed by manipulating the Latent Variables of the trained nueral network.</p>
</div>

 <div style="position:relative;padding-top:5%; padding-bottom:10%;">
<video width="100%" height="100%" controls>
      <source src="{{ site.github.url }}/assets/vid/Plantmodel Footsteps.m4v" type="video/mp4" >
      Your browser does not support the video tag.
</video>
<p style="text-align: center; color: gray;">Creating grass footstep sounds with the Plant Model v2.</p>
</div>

## Datamind Audio
<h3 style="color: gray;">Model Reliability Engineer</h3>

As a Model Reliability Engineer at DataMind Audio, I helped maintain and train neural audio models. At <a href="https://datamindaudio.ai/">DataMind Audio</a>, we present a groundbreaking real-time neural audio synthesis integrated seamlessly into your Digital Audio Workstation (DAW). Simply input any audio signal, and watch as our plugin recreates its timbre, drawing from meticulously curated datasets crafted in collaboration with leading sound designers and music producers. What sets us apart is our exclusive use of neural networks—no samples involved. This avant-garde synthesis process empowers users to delve into the infinite possibilities of an "Artist Brain." Moreover, our platform is committed to ethical sourcing, guaranteeing that artists receive proper compensation for their invaluable contributions to the dataset.  I was also fortunate to lead a workshop and demo at the <a href="https://ctsg.scot/demonstrators2024.html#:~:text=EXHIBITOR%3A-,YASHIQUE%20CHALIL,-At%20DataMind%20Audio">Creative Tech Scotland Gathering 2024.</a>, where I showcased some of these advancements.

Articles: <a href="https://gearspace.com/board/product-alerts-older-than-2-months/1425481-datamind-audio-unveils-virtual-ai-instrument-ethically-sourced-artist-brains.html">Gearspace</a>, <a href="https://www.musicradar.com/news/datamind-audio-combobulator">Music Radar</a>
 


